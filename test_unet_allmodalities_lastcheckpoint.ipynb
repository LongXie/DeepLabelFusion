{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jan  6 11:05:15 2020\n",
    "\n",
    "@author: sadhana-ravikumar\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import loss as l\n",
    "import nibabel as nib\n",
    "import os.path as osp\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import utils.preprocess_data as p\n",
    "from model.model import get_model\n",
    "import model.utils as utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config.runconfig as runconfig \n",
    "c = runconfig.Config_Run()\n",
    "\n",
    "# Load and log experiment configuration\n",
    "import yaml\n",
    "config = yaml.safe_load(open(c.config_file, 'r'))\n",
    "\n",
    "from utils.gen_utils import get_logger\n",
    "logger = get_logger('UNet3DPredict')\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "#DEFAULT_DEVICE = \"cpu\"\n",
    "device = config.get('device', DEFAULT_DEVICE)\n",
    "config['device'] = torch.device(device)\n",
    "torch.cuda.set_device(1)\n",
    "print(device)\n",
    "\n",
    "def computeGeneralizedDSC(gt, seg):\n",
    "\n",
    "    gt_seg = gt[gt > 0]\n",
    "    myseg = seg[gt > 0]\n",
    "\n",
    "    gdsc = 100*(sum(gt_seg == myseg)/ len(gt_seg))\n",
    "\n",
    "    return gdsc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-11 15:35:34,653 [MainThread] INFO UNet3DPredict - Loading model from /home/lxie/MultiModalDL//UNet/fold_0/model/run_502/last_checkpoint.pytorch...\n",
      "2021-08-11 15:35:36,488 [MainThread] INFO UNet3DPredict - Sending the model to 'cuda:1'\n",
      "LabelfusionUNet3DLabelWeightFineTunningUNetPerChannelSkipMaskCoordMapsBothDeepSupervision4LevelReLu(\n",
      "  (encoders): ModuleList(\n",
      "    (0): DownConv(\n",
      "      (conv1): Conv3d(7, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): DownConv(\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): DownConv(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): UpConv(\n",
      "      (upconv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpConv(\n",
      "      (upconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (inter_activation): Sigmoid()\n",
      "  (tunning_encoders): ModuleList(\n",
      "    (0): DownConv(\n",
      "      (conv1): Conv3d(18, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): DownConv(\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): DownConv(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): DownConv(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (tunning_decoders): ModuleList(\n",
      "    (0): UpConv(\n",
      "      (upconv): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpConv(\n",
      "      (upconv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): UpConv(\n",
      "      (upconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (tunning_final_conv): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (tunning_ds_uplayers0): ModuleList(\n",
      "    (0): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (tunning_ds_uplayers1): ModuleList(\n",
      "    (0): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (tunning_ds_uplayers2): ModuleList(\n",
      "    (0): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (final_activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load unet model\n",
    "model = get_model(config)\n",
    "model_file = c.checkpointDir + '/last_checkpoint.pytorch'\n",
    "logger.info(f'Loading model from {model_file}...')\n",
    "utils.load_checkpoint(model_file, model, config)\n",
    "logger.info(f\"Sending the model to '{device}'\")\n",
    "model = model.to(device)\n",
    "#model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject flip_118982_20160915 left (1/12) in test.\n",
      "torch.Size([2, 35, 72, 72, 72]) batch size: 2).\n",
      "34\n",
      "2\n",
      "torch.Size([68, 4, 72, 72, 72])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.03 GiB (GPU 1; 23.69 GiB total capacity; 16.06 GiB already allocated; 2.85 GiB free; 19.52 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43ba862cd03b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0;31m# forward pass with both modalities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_atlases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdeep_supervision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/lxie/MultiModalDL/UNet/python_code/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, segs, coordmaps, device)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;31m# Pass the output from the corresponding encoder step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mbefore_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mxinput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxinput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mweightmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxinput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/lxie/MultiModalDL/UNet/python_code/model/unet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, from_encoder)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Double convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.03 GiB (GPU 1; 23.69 GiB total capacity; 16.06 GiB already allocated; 2.85 GiB free; 19.52 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# predict the targets first \n",
    "# reorganize data so that it can be read to used by data loader\n",
    "reorganize_config = config['reorganize']\n",
    "half_patch = np.ceil((np.array(reorganize_config['patch_size']) - 1) / 2).astype(np.int32)\n",
    "loaders_config = config['loaders']\n",
    "trainer_config = config['trainer']\n",
    "deep_supervision = trainer_config.get('deep_supervision', False)\n",
    "preserve_size = trainer_config.get('preserve_size', False)\n",
    "model_config = config['model']\n",
    "model_padding = model_config.get('padding', 1)\n",
    "model_num_levels = model_config['num_levels']\n",
    "num_class = config['model']['out_channels']\n",
    "modality = loaders_config.get('modality', 'both')\n",
    "\n",
    "# check whether atlases are included\n",
    "reorganize_config = config['reorganize']\n",
    "with_atlas = reorganize_config.get('with_atlas', False)\n",
    "\n",
    "# generate folder saving information for each patch\n",
    "c.force_create(c.predictDir)\n",
    "\n",
    "# csv file\n",
    "with torch.no_grad():\n",
    "    #for phase in ['training', 'test']:\n",
    "    for phase in ['test']:\n",
    "\n",
    "        subjdirs = glob.glob(c.rawdataDir + \"/\" + phase + '/*')\n",
    "        Nsubj = len(subjdirs)\n",
    "        \n",
    "        for nsubj in range(Nsubj):\n",
    "            \n",
    "            subjdir = subjdirs[nsubj]\n",
    "            subjid = subjdir.split('/')[-1]\n",
    "\n",
    "\n",
    "            for side in ['left', 'right']:\n",
    "\n",
    "                # output current status\n",
    "                print(\"Subject \" + subjid + \" \" + side + \" (\" + str(nsubj+1) + \"/\" + str(Nsubj) + \") in \" + phase + \".\")\n",
    "                        \n",
    "                # read T1 T2 and refseg images\n",
    "                TargetT1 = os.path.join(c.rawdataDir, phase, subjid, 'mprage_to_tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "                TimgT1hdr = nib.load(TargetT1)\n",
    "                affine = TimgT1hdr.affine\n",
    "                TimgT1 = TimgT1hdr.get_fdata()\n",
    "                TargetT2 = os.path.join(c.rawdataDir, phase, subjid, 'tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "                TimgT2 = nib.load(TargetT2).get_fdata()\n",
    "                TargetSeg = os.path.join(c.rawdataDir, phase, subjid, 'refseg_' + side + '_chunk_resampled.nii.gz')\n",
    "                Tseg = nib.load(TargetSeg).get_fdata()\n",
    "\n",
    "                #plt.imshow(TimgT2[:,36,:])\n",
    "                #plt.show()\n",
    "                \n",
    "                # get coordinate maps\n",
    "                sizex, sizey, sizez = TimgT1.shape\n",
    "                xcoordmap = np.zeros(TimgT1.shape)\n",
    "                for x in range(sizex):\n",
    "                    xcoordmap[x,:,:] = 2*x/sizex - 1\n",
    "                ycoordmap = np.zeros(TimgT1.shape)\n",
    "                for y in range(sizey):\n",
    "                    ycoordmap[:,y,:] = 2*y/sizey - 1\n",
    "                zcoordmap = np.zeros(TimgT1.shape)\n",
    "                for z in range(sizez):\n",
    "                    zcoordmap[:,:,z] = 2*z/sizez - 1\n",
    "                coordmaps = np.stack((xcoordmap, ycoordmap, zcoordmap), axis = 3)\n",
    "                \n",
    "                # array for all the images and segmentations\n",
    "                if modality == 'T1':\n",
    "                    img = TimgT1[..., np.newaxis]\n",
    "                elif modality == 'T2':\n",
    "                    img = TimgT2[..., np.newaxis]\n",
    "                elif modality == \"both\":\n",
    "                    img = np.stack((TimgT1, TimgT2), axis = 3)\n",
    "                else:\n",
    "                    print(\"Not supported modality input\" + modality)\n",
    "                    exit\n",
    "                seg = Tseg[..., np.newaxis]\n",
    "\n",
    "                if with_atlas:\n",
    "                    for atlasdir in glob.glob(os.path.join(subjdir, 'multiatlas', 'tseg_' + side + '_train*')):\n",
    "\n",
    "                        # output current status\n",
    "                        atlasid = atlasdir.split('/')[-1]\n",
    "                        idx = atlasid.split('train')[-1]\n",
    "                        #print(\"    Sampling atlas:\" + atlasid)\n",
    "\n",
    "                        # read atlas T1 T2 and segmentation\n",
    "                        if modality == 'T1' or modality == 'both':\n",
    "                            AtlasT1 = os.path.join(atlasdir, 'atlas_to_native_mprage_resampled.nii.gz')\n",
    "                            AimgT1 = nib.load(AtlasT1).get_fdata()\n",
    "                        if modality == 'T2' or modality == 'both':\n",
    "                            AtlasT2 = os.path.join(atlasdir, 'atlas_to_native_resampled.nii.gz')\n",
    "                            AimgT2 = nib.load(AtlasT2).get_fdata()\n",
    "                        AtlasSeg = os.path.join(atlasdir, 'atlas_to_native_segvote_resampled.nii.gz')\n",
    "                        Aseg = nib.load(AtlasSeg).get_fdata()\n",
    "\n",
    "                        # concatenate all images together\n",
    "                        AimgT1 = AimgT1[..., np.newaxis]\n",
    "                        AimgT2 = AimgT2[..., np.newaxis]\n",
    "                        if modality == 'T1':\n",
    "                            img = np.concatenate((img, AimgT1), axis = 3)\n",
    "                        elif modality == 'T2':\n",
    "                            img = np.concatenate((img, AimgT2), axis = 3)\n",
    "                        elif modality == 'both':\n",
    "                            img = np.concatenate((img, AimgT1, AimgT2), axis = 3)\n",
    "                        Aseg = Aseg[..., np.newaxis]\n",
    "                        seg = np.concatenate((seg, Aseg), axis = 3)\n",
    "                \n",
    "                # sample patches and perform pre autmentation\n",
    "                img = np.rollaxis(img, 3, 0)\n",
    "                seg = np.rollaxis(seg, 3, 0)\n",
    "                coordmaps = np.rollaxis(coordmaps, 3, 0)\n",
    "                idside = subjid + '_' + side\n",
    "                sample_phase = 'test'\n",
    "                sample = {'id': idside, 'image': img, 'seg': seg, 'coordmaps': coordmaps, 'affine': affine, 'type': sample_phase}\n",
    "                test_patches = p.GeneratePatches(sample, reorganize_config)\n",
    "                test_batch_size = loaders_config['test_batch_size']\n",
    "                testloader = DataLoader(test_patches, batch_size = test_batch_size, shuffle = False, num_workers = loaders_config['num_workers'])\n",
    "\n",
    "                image_shape = sample['image'].shape[1:]\n",
    "                im_shape_pad = image_shape + half_patch * 2\n",
    "                prob = np.zeros([num_class] + list(im_shape_pad))\n",
    "                prob_T1 = np.zeros([num_class] + list(im_shape_pad))\n",
    "                prob_T2 = np.zeros([num_class] + list(im_shape_pad))\n",
    "                rep = np.zeros([num_class] + list(im_shape_pad))\n",
    "                pred_list = []\n",
    "\n",
    "                for z, patch_batched in enumerate(testloader):\n",
    "\n",
    "                    print(\"    Batch \" + str(z) + \" of \" + str(len(testloader)) + \" batches (test batch size: \" + str(test_batch_size) + \").\", end=\"\\r\")\n",
    "                    img = patch_batched['image']\n",
    "                    seg = patch_batched['seg']\n",
    "                    coordmaps = patch_batched['coordmaps']\n",
    "                    cpts = patch_batched['cpt']\n",
    "\n",
    "                    # pad image if needed\n",
    "                    if preserve_size:\n",
    "                        if model_padding == 0:\n",
    "                            pad_size = 0\n",
    "                            for ii in range(model_num_levels):\n",
    "                                pad_size = pad_size + 4*2**ii\n",
    "                            pad_size = pad_size - 2*2**ii\n",
    "                            img = F.pad(input=img, pad=(pad_size,pad_size,pad_size,pad_size,pad_size,pad_size), mode='constant', value=0)\n",
    "                            coordmaps = F.pad(input=coordmaps, pad=(pad_size,pad_size,pad_size,pad_size,pad_size,pad_size), mode='constant', value=0)\n",
    "        \n",
    "        \n",
    "                    # perform perdiction based on the training method.\n",
    "                    if with_atlas:\n",
    "        \n",
    "                        # reorganize the patches\n",
    "                        nbt, npt, nx, ny, nz = seg.size()\n",
    "                        natlas = seg.shape[1] - 1\n",
    "                        nmodality = int(img.shape[1]/natlas)\n",
    "                        seg_targets = seg[:, 0, ...]\n",
    "                        pat_targets = img[:, 0:nmodality, ...]\n",
    "                        seg_atlases = seg[:, 1:npt, ...]\n",
    "                        pat_atlases = img[:, nmodality:(nmodality*npt), ...]\n",
    "\n",
    "                        # move data to cuda if available\n",
    "                        seg_atlases = seg_atlases.to(device)\n",
    "                        seg_targets = seg_targets.to(device)\n",
    "                        pat_atlases = pat_atlases.to(device)\n",
    "                        pat_targets = pat_targets.to(device)\n",
    "                        coordmaps = coordmaps.to(device)\n",
    "\n",
    "                        # generate model input\n",
    "                        model_input = None\n",
    "                        for i in range(nbt):\n",
    "                            for j in range(npt-1):\n",
    "                                pat_atlas = pat_atlases[i:i+1, nmodality*j:nmodality*(j+1), ...]\n",
    "                                pat_target = pat_targets[i:i+1, ...]\n",
    "                                pat = torch.cat((pat_target, pat_atlas), dim = 1)\n",
    "                                if model_input is None:\n",
    "                                    model_input = pat\n",
    "                                else:\n",
    "                                    model_input = torch.cat((model_input, pat), dim = 0)\n",
    "\n",
    "                        # forward pass with both modalities\n",
    "                        output, _, _ = model(model_input, seg_atlases, coordmaps, device)\n",
    "                        if deep_supervision:\n",
    "                            output = output[-1]\n",
    "                            \n",
    "                        inter_sigmoid = model_config.get('inter_sigmoid', False)\n",
    "                        if model_config['fine_tunning_layers']:\n",
    "                            if model_config['final_sigmoid']:\n",
    "                                probability = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "                        else:\n",
    "                            if inter_sigmoid:\n",
    "                                probability = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                        if modality == 'T1' or modality == 'T2':\n",
    "                        \n",
    "                            # No need to perform multitmodal testing\n",
    "                            probability_T1 = probability\n",
    "                            probability_T2 = probability\n",
    "                            \n",
    "                        else:\n",
    "                               \n",
    "                            # forward pass with both only T1\n",
    "                            model_input_T1 = model_input * 1.0\n",
    "                            model_input_T1[:, 1:2, :, :, :] = torch.randn(nbt*natlas, 1, nx, ny, nz, device=device)\n",
    "                            model_input_T1[:, 3:4, :, :, :] = torch.randn(nbt*natlas, 1, nx, ny, nz, device=device)\n",
    "                            output, _, _ = model(model_input_T1, seg_atlases, coordmaps, device)\n",
    "                            if deep_supervision:\n",
    "                                output = output[-1]\n",
    "\n",
    "                            if model_config['fine_tunning_layers']:\n",
    "                                if model_config['final_sigmoid']:\n",
    "                                    probability_T1 = output.cpu().numpy()\n",
    "                                else:\n",
    "                                    probability_T1 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "                            else:\n",
    "                                if inter_sigmoid:\n",
    "                                    probability_T1 = output.cpu().numpy()\n",
    "                                else:\n",
    "                                    probability_T1 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                            # forward pass with both only T2\n",
    "                            model_input_T2 = model_input * 1.0\n",
    "                            model_input_T2[:, 0:1, :, :, :] = torch.randn(nbt*natlas, 1, nx, ny, nz, device=device)\n",
    "                            model_input_T2[:, 2:3, :, :, :] = torch.randn(nbt*natlas, 1, nx, ny, nz, device=device)\n",
    "                            output, _, _ = model(model_input_T2, seg_atlases, coordmaps, device)\n",
    "                            if deep_supervision:\n",
    "                                output = output[-1]\n",
    "\n",
    "                            if model_config['fine_tunning_layers']:\n",
    "                                if model_config['final_sigmoid']:\n",
    "                                    probability_T2 = output.cpu().numpy()\n",
    "                                else:\n",
    "                                    probability_T2 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "                            else:\n",
    "                                if inter_sigmoid:\n",
    "                                    probability_T2 = output.cpu().numpy()\n",
    "                                else:\n",
    "                                    probability_T2 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                                    \n",
    "                            # delete some variables\n",
    "                            del model_input_T1\n",
    "                            del model_input_T2\n",
    "                            \n",
    "                        # delete some variables\n",
    "                        del seg_atlases\n",
    "                        del seg_targets\n",
    "                        del pat_atlases\n",
    "                        del pat_targets\n",
    "                        del model_input\n",
    "                        del coordmaps\n",
    "                        #del weightmaps\n",
    "                        del output\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "                    else: \n",
    "                \n",
    "                        # forward pass with both modalities\n",
    "                        input = torch.cat((img, coordmaps), dim = 1).type(torch.cuda.FloatTensor)\n",
    "                        output = model(input)\n",
    "                        if deep_supervision:\n",
    "                            output = output[-1]\n",
    "\n",
    "                        if model_config['final_sigmoid']:\n",
    "                            probability = output.cpu().numpy()\n",
    "                        else:\n",
    "                            probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                        if modality == 'T1' or modality == 'T2':\n",
    "                        \n",
    "                            # No need to perform multitmodal testing\n",
    "                            probability_T1 = probability\n",
    "                            probability_T2 = probability\n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            # forward pass with only T1\n",
    "                            img_T1 = img * 1.0\n",
    "                            img_T1[:,1:2,:,:,:] = torch.randn(nbatch, 1, nx, ny, nz, device=device)\n",
    "                            input = torch.cat((img_T1, coordmaps), dim = 1).type(torch.cuda.FloatTensor)\n",
    "                            output = model(input)\n",
    "                            if deep_supervision:\n",
    "                                output = output[-1]\n",
    "\n",
    "                            if model_config['final_sigmoid']:\n",
    "                                probability_T1 = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability_T1 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                            # forward pass with only T2\n",
    "                            img_T2 = img * 1.0\n",
    "                            img_T2[:,0:1,:,:,:] = torch.randn(nbatch, 1, nx, ny, nz, device=device)\n",
    "                            input = torch.cat((img_T2, coordmaps), dim = 1).type(torch.cuda.FloatTensor)\n",
    "                            output = model(input)\n",
    "                            if deep_supervision:\n",
    "                                output = output[-1]\n",
    "\n",
    "                            if model_config['final_sigmoid']:\n",
    "                                probability_T2 = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability_T2 = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "                        \n",
    "                    \n",
    "                    #Crop the patch to only use the center part\n",
    "                    patch_crop_size = reorganize_config['patch_crop_size']\n",
    "                    if patch_crop_size > 0:\n",
    "                        probability = probability[:,:,patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size]\n",
    "                   \n",
    "                        probability_T1 = probability_T1[:,:,patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size]\n",
    "                        \n",
    "                        probability_T2 = probability_T2[:,:,patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size]\n",
    "                        \n",
    "                    ## Assemble image in loop!\n",
    "                    n, C, hp, wp, dp = probability.shape\n",
    "                    half_shape = torch.tensor([hp, wp, dp])/2\n",
    "                    hs, ws, ds = half_shape.type(torch.int)\n",
    "\n",
    "                    for cpt, pred, pred_T1, pred_T2 in zip(list(cpts), list(probability), list(probability_T1), list(probability_T2)):\n",
    "                        #if np.sum(pred)/hs/ws/ds < 0.1:\n",
    "                        prob[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += pred\n",
    "                        prob_T1[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += pred_T1\n",
    "                        prob_T2[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += pred_T2\n",
    "                        rep[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += 1\n",
    "\n",
    "                #Crop the image since we added padding when generating patches\n",
    "                prob = prob[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                prob_T1 = prob_T1[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                prob_T2 = prob_T2[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                rep = rep[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                rep[rep==0] = 1e-6\n",
    "\n",
    "                # Normalized by repetition\n",
    "                prob = prob/rep\n",
    "                seg_pred = np.argmax(prob, axis = 0).astype('float')\n",
    "                prob_T1 = prob_T1/rep\n",
    "                seg_pred_T1 = np.argmax(prob_T1, axis = 0).astype('float')\n",
    "                prob_T2 = prob_T2/rep\n",
    "                seg_pred_T2 = np.argmax(prob_T2, axis = 0).astype('float')\n",
    "\n",
    "                # compute gdsc\n",
    "                gdsc = computeGeneralizedDSC(Tseg, seg_pred)\n",
    "                sys.stdout.write(\"\\033[F\") #back to previous line \n",
    "                sys.stdout.write(\"\\033[K\") #clear line \n",
    "                print(\"    Prediction accuracy both: \", gdsc)\n",
    "                \n",
    "                gdsc_T1 = computeGeneralizedDSC(Tseg, seg_pred_T1)\n",
    "                print(\"    Prediction accuracy only T1: \", gdsc_T1)\n",
    "                \n",
    "                gdsc_T2 = computeGeneralizedDSC(Tseg, seg_pred_T2)\n",
    "                print(\"    Prediction accuracy only T2: \", gdsc_T2)\n",
    "\n",
    "                #nib.save(nib.Nifti1Image(prob, affine), osp.join(c.predictDir, phase + \"_prob_\" + str(subjid) + \"_\" + side + \"_target.nii.gz\"))\n",
    "                nib.save(nib.Nifti1Image(seg_pred, affine), osp.join(c.predictDir, phase + \"_seg_\" + str(subjid) + \"_\" + side + \"_target_both.nii.gz\" ))\n",
    "                nib.save(nib.Nifti1Image(seg_pred_T1, affine), osp.join(c.predictDir, phase + \"_seg_\" + str(subjid) + \"_\" + side + \"_target_onlyT1.nii.gz\" ))\n",
    "                nib.save(nib.Nifti1Image(seg_pred_T2, affine), osp.join(c.predictDir, phase + \"_seg_\" + str(subjid) + \"_\" + side + \"_target_onlyT2.nii.gz\" ))\n",
    "\n",
    "\n",
    "print('Done')\n",
    "                \n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
