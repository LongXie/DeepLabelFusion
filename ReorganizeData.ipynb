{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import csv\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import random\n",
    "import utils.preprocess_data as p\n",
    "\n",
    "# load configuration\n",
    "import yaml\n",
    "import config.runconfig as runconfig \n",
    "c = runconfig.Config_Run()\n",
    "\n",
    "# Load and log experiment configuration\n",
    "import torch\n",
    "config = yaml.safe_load(open(c.config_file, 'r'))\n",
    "\n",
    "# Set up GPU if available\n",
    "DEFAULT_DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = config.get('device', DEFAULT_DEVICE)\n",
    "config['device'] = torch.device(device)\n",
    "print(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training left flip_102904_20170509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-80d86f2574b0>:25: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  TimgT1 = TimgT1hdr.get_data()\n",
      "<ipython-input-2-80d86f2574b0>:27: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  TimgT2 = nib.load(TargetT2).get_data()\n",
      "<ipython-input-2-80d86f2574b0>:29: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  Tseg = nib.load(TargetSeg).get_data()\n",
      "<ipython-input-2-80d86f2574b0>:58: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  AimgT1 = nib.load(AtlasT1).get_data()\n",
      "<ipython-input-2-80d86f2574b0>:60: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  AimgT2 = nib.load(AtlasT2).get_data()\n",
      "<ipython-input-2-80d86f2574b0>:62: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  Aseg = nib.load(AtlasSeg).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject flip_102904_20170509_left(train)\n",
      "Reading training right flip_102904_20170509\n",
      "Processing subject flip_102904_20170509_right(train)\n",
      "Reading training left orig_114787_20160525\n",
      "Processing subject orig_114787_20160525_left(train)\n",
      "Reading training right orig_114787_20160525\n",
      "Processing subject orig_114787_20160525_right(train)\n",
      "Reading training left flip_104504_20160516\n",
      "Processing subject flip_104504_20160516_left(train)\n",
      "Reading training right flip_104504_20160516\n",
      "Processing subject flip_104504_20160516_right(train)\n",
      "Reading training left flip_119582_20170223\n",
      "Processing subject flip_119582_20170223_left(train)\n",
      "Reading training right flip_119582_20170223\n",
      "Processing subject flip_119582_20170223_right(train)\n",
      "Reading training left flip_121329_20170216\n",
      "Processing subject flip_121329_20170216_left(train)\n",
      "Reading training right flip_121329_20170216\n",
      "Processing subject flip_121329_20170216_right(train)\n",
      "Reading training left flip_119655_20170504\n",
      "Processing subject flip_119655_20170504_left(train)\n",
      "Reading training right flip_119655_20170504\n",
      "Processing subject flip_119655_20170504_right(train)\n",
      "Reading training left orig_102904_20170509\n",
      "Processing subject orig_102904_20170509_left(train)\n",
      "Reading training right orig_102904_20170509\n",
      "Processing subject orig_102904_20170509_right(train)\n",
      "Reading training left orig_118601_20170509\n",
      "Processing subject orig_118601_20170509_left(train)\n",
      "Reading training right orig_118601_20170509\n",
      "Processing subject orig_118601_20170509_right(train)\n",
      "Reading training left flip_118601_20170509\n",
      "Processing subject flip_118601_20170509_left(train)\n",
      "Reading training right flip_118601_20170509\n",
      "Processing subject flip_118601_20170509_right(train)\n",
      "Reading training left orig_109789_20160915\n",
      "Processing subject orig_109789_20160915_left(train)\n",
      "Reading training right orig_109789_20160915\n",
      "Processing subject orig_109789_20160915_right(train)\n",
      "Reading training left flip_113066_02_20161117\n",
      "Processing subject flip_113066_02_20161117_left(train)\n",
      "Reading training right flip_113066_02_20161117\n",
      "Processing subject flip_113066_02_20161117_right(train)\n",
      "Reading training left orig_120200_20170620\n",
      "Processing subject orig_120200_20170620_left(train)\n",
      "Reading training right orig_120200_20170620\n",
      "Processing subject orig_120200_20170620_right(train)\n",
      "Reading training left orig_119788_20160818\n",
      "Processing subject orig_119788_20160818_left(train)\n",
      "Reading training right orig_119788_20160818\n",
      "Processing subject orig_119788_20160818_right(train)\n",
      "Reading training left orig_116497_20160425\n",
      "Processing subject orig_116497_20160425_left(train)\n",
      "Reading training right orig_116497_20160425\n",
      "Processing subject orig_116497_20160425_right(train)\n",
      "Reading training left flip_114787_20160525\n",
      "Processing subject flip_114787_20160525_left(train)\n",
      "Reading training right flip_114787_20160525\n",
      "Processing subject flip_114787_20160525_right(train)\n",
      "Reading training left orig_119655_20170504\n",
      "Processing subject orig_119655_20170504_left(train)\n",
      "Reading training right orig_119655_20170504\n",
      "Processing subject orig_119655_20170504_right(train)\n",
      "Reading training left flip_116497_20160425\n",
      "Processing subject flip_116497_20160425_left(train)\n",
      "Reading training right flip_116497_20160425\n",
      "Processing subject flip_116497_20160425_right(train)\n",
      "Reading training left orig_100049_20160621\n",
      "Processing subject orig_100049_20160621_left(train)\n",
      "Reading training right orig_100049_20160621\n",
      "Processing subject orig_100049_20160621_right(train)\n",
      "Reading training left orig_118711_20160412\n",
      "Processing subject orig_118711_20160412_left(train)\n",
      "Reading training right orig_118711_20160412\n",
      "Processing subject orig_118711_20160412_right(train)\n",
      "Reading training left orig_121329_20170216\n",
      "Processing subject orig_121329_20170216_left(train)\n",
      "Reading training right orig_121329_20170216\n",
      "Processing subject orig_121329_20170216_right(train)\n",
      "Reading training left flip_101162_20160523\n",
      "Processing subject flip_101162_20160523_left(train)\n",
      "Reading training right flip_101162_20160523\n",
      "Processing subject flip_101162_20160523_right(train)\n",
      "Reading training left flip_118060_20161010\n",
      "Processing subject flip_118060_20161010_left(train)\n",
      "Reading training right flip_118060_20161010\n",
      "Processing subject flip_118060_20161010_right(train)\n",
      "Reading training left orig_113066_02_20161117\n",
      "Processing subject orig_113066_02_20161117_left(train)\n",
      "Reading training right orig_113066_02_20161117\n",
      "Processing subject orig_113066_02_20161117_right(train)\n",
      "Reading training left flip_109789_20160915\n",
      "Processing subject flip_109789_20160915_left(train)\n",
      "Reading training right flip_109789_20160915\n",
      "Processing subject flip_109789_20160915_right(train)\n",
      "Reading training left orig_118060_20161010\n",
      "Processing subject orig_118060_20161010_left(train)\n",
      "Reading training right orig_118060_20161010\n",
      "Processing subject orig_118060_20161010_right(train)\n",
      "Reading training left flip_120200_20170620\n",
      "Processing subject flip_120200_20170620_left(train)\n",
      "Reading training right flip_120200_20170620\n",
      "Processing subject flip_120200_20170620_right(train)\n",
      "Reading training left flip_119788_20160818\n",
      "Processing subject flip_119788_20160818_left(train)\n",
      "Reading training right flip_119788_20160818\n",
      "Processing subject flip_119788_20160818_right(train)\n",
      "Reading training left flip_100049_20160621\n",
      "Processing subject flip_100049_20160621_left(train)\n",
      "Reading training right flip_100049_20160621\n",
      "Processing subject flip_100049_20160621_right(train)\n",
      "Reading training left orig_119851_20170606\n",
      "Processing subject orig_119851_20170606_left(train)\n",
      "Reading training right orig_119851_20170606\n",
      "Processing subject orig_119851_20170606_right(train)\n",
      "Reading training left orig_119582_20170223\n",
      "Processing subject orig_119582_20170223_left(train)\n",
      "Reading training right orig_119582_20170223\n",
      "Processing subject orig_119582_20170223_right(train)\n",
      "Reading training left flip_119851_20170606\n",
      "Processing subject flip_119851_20170606_left(train)\n",
      "Reading training right flip_119851_20170606\n",
      "Processing subject flip_119851_20170606_right(train)\n",
      "Reading training left orig_104504_20160516\n",
      "Processing subject orig_104504_20160516_left(train)\n",
      "Reading training right orig_104504_20160516\n",
      "Processing subject orig_104504_20160516_right(train)\n",
      "Reading training left flip_118711_20160412\n",
      "Processing subject flip_118711_20160412_left(train)\n",
      "Reading training right flip_118711_20160412\n",
      "Processing subject flip_118711_20160412_right(train)\n",
      "Reading training left orig_101162_20160523\n",
      "Processing subject orig_101162_20160523_left(train)\n",
      "Reading training right orig_101162_20160523\n",
      "Processing subject orig_101162_20160523_right(train)\n",
      "Reading test left flip_118982_20160915\n",
      "Processing subject flip_118982_20160915_left(val)\n",
      "Reading test right flip_118982_20160915\n",
      "Processing subject flip_118982_20160915_right(val)\n",
      "Reading test left orig_119254_20160428\n",
      "Processing subject orig_119254_20160428_left(val)\n",
      "Reading test right orig_119254_20160428\n",
      "Processing subject orig_119254_20160428_right(val)\n",
      "Reading test left flip_100113_20160620\n",
      "Processing subject flip_100113_20160620_left(val)\n",
      "Reading test right flip_100113_20160620\n",
      "Processing subject flip_100113_20160620_right(val)\n",
      "Reading test left flip_113870_20160711\n",
      "Processing subject flip_113870_20160711_left(val)\n",
      "Reading test right flip_113870_20160711\n",
      "Processing subject flip_113870_20160711_right(val)\n",
      "Reading test left orig_120184_20160426\n",
      "Processing subject orig_120184_20160426_left(val)\n",
      "Reading test right orig_120184_20160426\n",
      "Processing subject orig_120184_20160426_right(val)\n",
      "Reading test left flip_119254_20160428\n",
      "Processing subject flip_119254_20160428_left(val)\n",
      "Reading test right flip_119254_20160428\n",
      "Processing subject flip_119254_20160428_right(val)\n",
      "Reading test left orig_113870_20160711\n",
      "Processing subject orig_113870_20160711_left(val)\n",
      "Reading test right orig_113870_20160711\n",
      "Processing subject orig_113870_20160711_right(val)\n",
      "Reading test left flip_120896_20170330\n",
      "Processing subject flip_120896_20170330_left(val)\n",
      "Reading test right flip_120896_20170330\n",
      "Processing subject flip_120896_20170330_right(val)\n",
      "Reading test left orig_120896_20170330\n",
      "Processing subject orig_120896_20170330_left(val)\n",
      "Reading test right orig_120896_20170330\n",
      "Processing subject orig_120896_20170330_right(val)\n",
      "Reading test left orig_118982_20160915\n",
      "Processing subject orig_118982_20160915_left(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test right orig_118982_20160915\n",
      "Processing subject orig_118982_20160915_right(val)\n",
      "Reading test left flip_120184_20160426\n",
      "Processing subject flip_120184_20160426_left(val)\n",
      "Reading test right flip_120184_20160426\n",
      "Processing subject flip_120184_20160426_right(val)\n",
      "Reading test left orig_100113_20160620\n",
      "Processing subject orig_100113_20160620_left(val)\n",
      "Reading test right orig_100113_20160620\n",
      "Processing subject orig_100113_20160620_right(val)\n"
     ]
    }
   ],
   "source": [
    "# reorganize data so that it can be read to used by data loader\n",
    "reorganize_config = config['reorganize']\n",
    "with_atlas = reorganize_config.get('with_atlas', False)\n",
    "\n",
    "# generate folder saving information for each patch\n",
    "c.force_create(c.patchesDir)\n",
    "c.force_create(c.patchesDataDir)\n",
    "\n",
    "# csv file\n",
    "for phase in ['training', 'test']:\n",
    "#for phase in [ 'test']:\n",
    "\n",
    "    for subjdir in glob.glob(c.rawdataDir + \"/\" + phase + '/*'):\n",
    "\n",
    "        for side in ['left', 'right']:\n",
    "\n",
    "            # output current status\n",
    "            subjid = subjdir.split('/')[-1]\n",
    "            print(\"Reading \" + phase + \" \" + side + \" {}\".format(subjid))\n",
    "\n",
    "            # read T1 T2 and refseg images\n",
    "            TargetT1 = os.path.join(c.rawdataDir, phase, subjid, 'mprage_to_tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "            TimgT1hdr = nib.load(TargetT1)\n",
    "            affine = TimgT1hdr.affine\n",
    "            TimgT1 = TimgT1hdr.get_fdata()\n",
    "            TargetT2 = os.path.join(c.rawdataDir, phase, subjid, 'tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "            TimgT2 = nib.load(TargetT2).get_fdata()\n",
    "            TargetSeg = os.path.join(c.rawdataDir, phase, subjid, 'refseg_' + side + '_chunk_resampled.nii.gz')\n",
    "            Tseg = nib.load(TargetSeg).get_fgdata()\n",
    "            \n",
    "            # get coordinate maps\n",
    "            sizex, sizey, sizez = TimgT1.shape\n",
    "            xcoordmap = np.zeros(TimgT1.shape)\n",
    "            for x in range(sizex):\n",
    "                xcoordmap[x,:,:] = 2*x/sizex - 1\n",
    "            ycoordmap = np.zeros(TimgT1.shape)\n",
    "            for y in range(sizey):\n",
    "                ycoordmap[:,y,:] = 2*y/sizey - 1\n",
    "            zcoordmap = np.zeros(TimgT1.shape)\n",
    "            for z in range(sizez):\n",
    "                zcoordmap[:,:,z] = 2*z/sizez - 1\n",
    "            coordmaps = np.stack((xcoordmap, ycoordmap, zcoordmap), axis = 3)\n",
    "            \n",
    "            # array for all the images and segmentations\n",
    "            img = np.stack((TimgT1, TimgT2), axis = 3)\n",
    "            seg = Tseg[..., np.newaxis]\n",
    "            \n",
    "            if with_atlas:\n",
    "                for atlasdir in glob.glob(os.path.join(subjdir, 'multiatlas', 'tseg_' + side + '_train*')):\n",
    "\n",
    "                    # output current status\n",
    "                    atlasid = atlasdir.split('/')[-1]\n",
    "                    idx = atlasid.split('train')[-1]\n",
    "                    #print(\"    Sampling atlas:\" + atlasid)\n",
    "\n",
    "                    # read atlas T1 T2 and segmentation\n",
    "                    AtlasT1 = os.path.join(atlasdir, 'atlas_to_native_mprage_resampled.nii.gz')\n",
    "                    AimgT1 = nib.load(AtlasT1).get_fdata()\n",
    "                    AtlasT2 = os.path.join(atlasdir, 'atlas_to_native_resampled.nii.gz')\n",
    "                    AimgT2 = nib.load(AtlasT2).get_fdata()\n",
    "                    AtlasSeg = os.path.join(atlasdir, 'atlas_to_native_segvote_resampled.nii.gz')\n",
    "                    Aseg = nib.load(AtlasSeg).get_fdata()\n",
    "\n",
    "                    # concatenate all images together\n",
    "                    AimgT1 = AimgT1[..., np.newaxis]\n",
    "                    AimgT2 = AimgT2[..., np.newaxis]\n",
    "                    img = np.concatenate((img, AimgT1, AimgT2), axis = 3)\n",
    "                    Aseg = Aseg[..., np.newaxis]\n",
    "                    seg = np.concatenate((seg, Aseg), axis = 3)\n",
    "\n",
    "            # sample patches and perform pre autmentation\n",
    "            img = np.rollaxis(img, 3, 0)\n",
    "            seg = np.rollaxis(seg, 3, 0)\n",
    "            coordmaps = np.rollaxis(coordmaps, 3, 0)\n",
    "            idside = subjid + '_' + side\n",
    "            if phase == 'training':\n",
    "                sample_phase = 'train'\n",
    "            else:\n",
    "                sample_phase = 'val'            \n",
    "            sample = {'id': idside, 'image': img, 'seg': seg, 'coordmaps': coordmaps, 'affine': affine, 'type': sample_phase}\n",
    "            print('Processing subject ' + str(sample['id']) + '(' + sample['type'] + ')')\n",
    "            p.GeneratePatches(sample, reorganize_config)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
