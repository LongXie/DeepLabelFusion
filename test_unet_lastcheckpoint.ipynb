{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jan  6 11:05:15 2020\n",
    "\n",
    "@author: sadhana-ravikumar\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import loss as l\n",
    "import nibabel as nib\n",
    "import os.path as osp\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import utils.preprocess_data as p\n",
    "from model.model import get_model\n",
    "import model.utils as utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config.runconfig as runconfig \n",
    "c = runconfig.Config_Run()\n",
    "\n",
    "# Load and log experiment configuration\n",
    "import yaml\n",
    "config = yaml.safe_load(open(c.config_file, 'r'))\n",
    "\n",
    "from utils.gen_utils import get_logger\n",
    "logger = get_logger('UNet3DPredict')\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "#DEFAULT_DEVICE = \"cpu\"\n",
    "device = config.get('device', DEFAULT_DEVICE)\n",
    "config['device'] = torch.device(device)\n",
    "torch.cuda.set_device(1)\n",
    "print(device)\n",
    "\n",
    "def computeGeneralizedDSC(gt, seg):\n",
    "\n",
    "    gt_seg = gt[gt > 0]\n",
    "    myseg = seg[gt > 0]\n",
    "\n",
    "    gdsc = 100*(sum(gt_seg == myseg)/ len(gt_seg))\n",
    "\n",
    "    return gdsc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 09:41:04,581 [MainThread] INFO UNet3DPredict - Loading model from /home/lxie/MultiModalDL//UNet/fold_0/model/run_500/last_checkpoint.pytorch...\n",
      "2021-07-13 09:41:06,573 [MainThread] INFO UNet3DPredict - Sending the model to 'cuda:1'\n",
      "LabelfusionUNet3DLabelWeightFineTunningUNetPerChannelSkipMaskCoordMapsBothDeepSupervision4LevelReLu(\n",
      "  (encoders): ModuleList(\n",
      "    (0): DownConv(\n",
      "      (conv1): Conv3d(7, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): DownConv(\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): DownConv(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): UpConv(\n",
      "      (upconv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpConv(\n",
      "      (upconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (inter_activation): Sigmoid()\n",
      "  (tunning_encoders): ModuleList(\n",
      "    (0): DownConv(\n",
      "      (conv1): Conv3d(18, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): DownConv(\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): DownConv(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): DownConv(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (tunning_decoders): ModuleList(\n",
      "    (0): UpConv(\n",
      "      (upconv): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): UpConv(\n",
      "      (upconv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): UpConv(\n",
      "      (upconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "      (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (dropout): Dropout3d(p=0.0, inplace=False)\n",
      "      (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (tunning_final_conv): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (tunning_ds_uplayers0): ModuleList(\n",
      "    (0): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (tunning_ds_uplayers1): ModuleList(\n",
      "    (0): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (tunning_ds_uplayers2): ModuleList(\n",
      "    (0): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv3d(32, 15, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      "  (final_activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load unet model\n",
    "model = get_model(config)\n",
    "model_file = c.checkpointDir + '/last_checkpoint.pytorch'\n",
    "logger.info(f'Loading model from {model_file}...')\n",
    "utils.load_checkpoint(model_file, model, config)\n",
    "logger.info(f\"Sending the model to '{device}'\")\n",
    "model = model.to(device)\n",
    "#model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject flip_118982_20160915 left (1/12) in test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F\u001b[K    Prediction accuracy:  82.33193009312413\n",
      "Subject flip_118982_20160915 right (1/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  83.52323094314458\n",
      "Subject orig_119254_20160428 left (2/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  81.87318489835431\n",
      "Subject orig_119254_20160428 right (2/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  83.9136827944374\n",
      "Subject flip_100113_20160620 left (3/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  81.09882722940449\n",
      "Subject flip_100113_20160620 right (3/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  74.41624746602598\n",
      "Subject flip_113870_20160711 left (4/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  70.03401578846031\n",
      "Subject flip_113870_20160711 right (4/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  77.42324627540866\n",
      "Subject orig_120184_20160426 left (5/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  77.78168688084438\n",
      "Subject orig_120184_20160426 right (5/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  80.54101709226596\n",
      "Subject flip_119254_20160428 left (6/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  83.19098346551536\n",
      "Subject flip_119254_20160428 right (6/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  80.92207163601162\n",
      "Subject orig_113870_20160711 left (7/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  72.86024488811147\n",
      "Subject orig_113870_20160711 right (7/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  68.14389320326039\n",
      "Subject flip_120896_20170330 left (8/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  77.65986922309654\n",
      "Subject flip_120896_20170330 right (8/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  80.88949249910239\n",
      "Subject orig_120896_20170330 left (9/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  80.07774083266989\n",
      "Subject orig_120896_20170330 right (9/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  77.70327681111235\n",
      "Subject orig_118982_20160915 left (10/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  82.16751652963134\n",
      "Subject orig_118982_20160915 right (10/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  83.43156014797806\n",
      "Subject flip_120184_20160426 left (11/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  78.68216332333749\n",
      "Subject flip_120184_20160426 right (11/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  76.5805635280684\n",
      "Subject orig_100113_20160620 left (12/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  74.54889005681108\n",
      "Subject orig_100113_20160620 right (12/12) in test.\n",
      "\u001b[F\u001b[K    Prediction accuracy:  78.86011979785611\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# predict the targets first \n",
    "# reorganize data so that it can be read to used by data loader\n",
    "reorganize_config = config['reorganize']\n",
    "half_patch = np.ceil((np.array(reorganize_config['patch_size']) - 1) / 2).astype(np.int32)\n",
    "loaders_config = config['loaders']\n",
    "trainer_config = config['trainer']\n",
    "deep_supervision = trainer_config.get('deep_supervision', False)\n",
    "preserve_size = trainer_config.get('preserve_size', False)\n",
    "model_config = config['model']\n",
    "model_padding = model_config.get('padding', 1)\n",
    "model_num_levels = model_config['num_levels']\n",
    "num_class = config['model']['out_channels']\n",
    "modality = loaders_config.get('modality', 'both')\n",
    "\n",
    "# check whether atlases are included\n",
    "reorganize_config = config['reorganize']\n",
    "with_atlas = reorganize_config.get('with_atlas', False)\n",
    "\n",
    "# generate folder saving information for each patch\n",
    "c.force_create(c.predictDir)\n",
    "\n",
    "# csv file\n",
    "with torch.no_grad():\n",
    "    #for phase in ['training', 'test']:\n",
    "    for phase in ['test']:\n",
    "\n",
    "        subjdirs = glob.glob(c.rawdataDir + \"/\" + phase + '/*')\n",
    "        Nsubj = len(subjdirs)\n",
    "        \n",
    "        for nsubj in range(Nsubj):\n",
    "            \n",
    "            subjdir = subjdirs[nsubj]\n",
    "            subjid = subjdir.split('/')[-1]\n",
    "\n",
    "\n",
    "            for side in ['left', 'right']:\n",
    "\n",
    "                # output current status\n",
    "                print(\"Subject \" + subjid + \" \" + side + \" (\" + str(nsubj+1) + \"/\" + str(Nsubj) + \") in \" + phase + \".\")\n",
    "                        \n",
    "                # read T1 T2 and refseg images\n",
    "                TargetT1 = os.path.join(c.rawdataDir, phase, subjid, 'mprage_to_tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "                TimgT1hdr = nib.load(TargetT1)\n",
    "                affine = TimgT1hdr.affine\n",
    "                TimgT1 = TimgT1hdr.get_fdata()\n",
    "                TargetT2 = os.path.join(c.rawdataDir, phase, subjid, 'tse_native_chunk_' + side + '_resampled.nii.gz')\n",
    "                TimgT2 = nib.load(TargetT2).get_fdata()\n",
    "                TargetSeg = os.path.join(c.rawdataDir, phase, subjid, 'refseg_' + side + '_chunk_resampled.nii.gz')\n",
    "                Tseg = nib.load(TargetSeg).get_fdata()\n",
    "\n",
    "                #plt.imshow(TimgT2[:,36,:])\n",
    "                #plt.show()\n",
    "                \n",
    "                # get coordinate maps\n",
    "                sizex, sizey, sizez = TimgT1.shape\n",
    "                xcoordmap = np.zeros(TimgT1.shape)\n",
    "                for x in range(sizex):\n",
    "                    xcoordmap[x,:,:] = 2*x/sizex - 1\n",
    "                ycoordmap = np.zeros(TimgT1.shape)\n",
    "                for y in range(sizey):\n",
    "                    ycoordmap[:,y,:] = 2*y/sizey - 1\n",
    "                zcoordmap = np.zeros(TimgT1.shape)\n",
    "                for z in range(sizez):\n",
    "                    zcoordmap[:,:,z] = 2*z/sizez - 1\n",
    "                coordmaps = np.stack((xcoordmap, ycoordmap, zcoordmap), axis = 3)\n",
    "                \n",
    "                # array for all the images and segmentations\n",
    "                if modality == 'T1':\n",
    "                    img = TimgT1[..., np.newaxis]\n",
    "                elif modality == 'T2':\n",
    "                    img = TimgT2[..., np.newaxis]\n",
    "                elif modality == \"both\":\n",
    "                    img = np.stack((TimgT1, TimgT2), axis = 3)\n",
    "                else:\n",
    "                    print(\"Not supported modality input\" + modality)\n",
    "                    exit\n",
    "                seg = Tseg[..., np.newaxis]\n",
    "                \n",
    "                if with_atlas:\n",
    "                    for atlasdir in glob.glob(os.path.join(subjdir, 'multiatlas', 'tseg_' + side + '_train*')):\n",
    "\n",
    "                        # output current status\n",
    "                        atlasid = atlasdir.split('/')[-1]\n",
    "                        idx = atlasid.split('train')[-1]\n",
    "                        #print(\"    Sampling atlas:\" + atlasid)\n",
    "\n",
    "                        # read atlas T1 T2 and segmentation\n",
    "                        if modality == 'T1' or modality == 'both':\n",
    "                            AtlasT1 = os.path.join(atlasdir, 'atlas_to_native_mprage_resampled.nii.gz')\n",
    "                            AimgT1 = nib.load(AtlasT1).get_data()\n",
    "                        if modality == 'T2' or modality == 'both':\n",
    "                            AtlasT2 = os.path.join(atlasdir, 'atlas_to_native_resampled.nii.gz')\n",
    "                            AimgT2 = nib.load(AtlasT2).get_data()\n",
    "                        AtlasSeg = os.path.join(atlasdir, 'atlas_to_native_segvote_resampled.nii.gz')\n",
    "                        Aseg = nib.load(AtlasSeg).get_data()\n",
    "\n",
    "                        # concatenate all images together\n",
    "                        AimgT1 = AimgT1[..., np.newaxis]\n",
    "                        AimgT2 = AimgT2[..., np.newaxis]\n",
    "                        if modality == 'T1':\n",
    "                            img = np.concatenate((img, AimgT1), axis = 3)\n",
    "                        elif modality == 'T2':\n",
    "                            img = np.concatenate((img, AimgT2), axis = 3)\n",
    "                        elif modality == 'both':\n",
    "                            img = np.concatenate((img, AimgT1, AimgT2), axis = 3)\n",
    "                        Aseg = Aseg[..., np.newaxis]\n",
    "                        seg = np.concatenate((seg, Aseg), axis = 3)\n",
    "                \n",
    "                # sample patches and perform pre autmentation\n",
    "                img = np.rollaxis(img, 3, 0)\n",
    "                seg = np.rollaxis(seg, 3, 0)                \n",
    "                coordmaps = np.rollaxis(coordmaps, 3, 0)\n",
    "                idside = subjid + '_' + side\n",
    "                sample_phase = 'test'\n",
    "                sample = {'id': idside, 'image': img, 'seg': seg, 'coordmaps': coordmaps, 'affine': affine, 'type': sample_phase}\n",
    "                test_patches = p.GeneratePatches(sample, reorganize_config)\n",
    "                test_batch_size = loaders_config['test_batch_size']\n",
    "                testloader = DataLoader(test_patches, batch_size = test_batch_size, shuffle = False, num_workers = loaders_config['num_workers'])\n",
    "\n",
    "                image_shape = sample['image'].shape[1:]\n",
    "                im_shape_pad = image_shape + half_patch * 2\n",
    "                prob = np.zeros([num_class] + list(im_shape_pad))\n",
    "                rep = np.zeros([num_class] + list(im_shape_pad))\n",
    "                pred_list = []\n",
    "\n",
    "                for z, patch_batched in enumerate(testloader):\n",
    "\n",
    "                    print(\"    Batch \" + str(z) + \" of \" + str(len(testloader)) + \" batches (test batch size: \" + str(test_batch_size) + \").\", end=\"\\r\")\n",
    "                    img = patch_batched['image'].to(device)\n",
    "                    seg = patch_batched['seg'].to(device)\n",
    "                    coordmaps = patch_batched['coordmaps'].to(device)\n",
    "                    cpts = patch_batched['cpt']\n",
    "\n",
    "                    # pad image if needed\n",
    "                    if preserve_size:\n",
    "                        if model_padding == 0:\n",
    "                            pad_size = 0\n",
    "                            for ii in range(model_num_levels):\n",
    "                                pad_size = pad_size + 4*2**ii\n",
    "                            pad_size = pad_size - 2*2**ii\n",
    "                            img = F.pad(input=img, pad=(pad_size,pad_size,pad_size,pad_size,pad_size,pad_size), mode='constant', value=0)\n",
    "                            coordmaps = F.pad(input=coordmaps, pad=(pad_size,pad_size,pad_size,pad_size,pad_size,pad_size), mode='constant', value=0)\n",
    "        \n",
    "                    # perform perdiction based on the training method.\n",
    "                    if with_atlas:\n",
    "                        \n",
    "                        # reorganize the patches\n",
    "                        nbt, npt, nx, ny, nz = seg.size()\n",
    "                        natlas = seg.shape[1] - 1\n",
    "                        nmodality = int(img.shape[1]/natlas)\n",
    "                        seg_targets = seg[:, 0, ...]\n",
    "                        pat_targets = img[:, 0:nmodality, ...]\n",
    "                        seg_atlases = seg[:, 1:npt, ...]\n",
    "                        pat_atlases = img[:, nmodality:(nmodality*npt), ...]\n",
    "\n",
    "                        # move data to cuda if available\n",
    "                        seg_atlases = seg_atlases.to(device)\n",
    "                        seg_targets = seg_targets.to(device)\n",
    "                        pat_atlases = pat_atlases.to(device)\n",
    "                        pat_targets = pat_targets.to(device)\n",
    "                        coordmaps = coordmaps.to(device)\n",
    "\n",
    "                        # generate model input\n",
    "                        model_input = None\n",
    "                        for i in range(nbt):\n",
    "                            for j in range(npt-1):\n",
    "                                pat_atlas = pat_atlases[i:i+1, nmodality*j:nmodality*(j+1), ...]\n",
    "                                pat_target = pat_targets[i:i+1, ...]\n",
    "                                pat = torch.cat((pat_target, pat_atlas), dim = 1)\n",
    "                                if model_input is None:\n",
    "                                    model_input = pat\n",
    "                                else:\n",
    "                                    model_input = torch.cat((model_input, pat), dim = 0)\n",
    "\n",
    "                        # forward pass\n",
    "                        output, _, _ = model(model_input, seg_atlases, coordmaps, device)\n",
    "                        if deep_supervision:\n",
    "                            output = output[-1]\n",
    "                            \n",
    "                        inter_sigmoid = model_config.get('inter_sigmoid', False)\n",
    "                        if model_config['fine_tunning_layers']:\n",
    "                            if model_config['final_sigmoid']:\n",
    "                                probability = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "                        else:\n",
    "                            if inter_sigmoid:\n",
    "                                probability = output.cpu().numpy()\n",
    "                            else:\n",
    "                                probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "\n",
    "\n",
    "                        # display weight maps\n",
    "                        #weightmaps = weightmaps.cpu().numpy()\n",
    "\n",
    "                        # delete some variables\n",
    "                        del seg_atlases\n",
    "                        del seg_targets\n",
    "                        del pat_atlases\n",
    "                        del pat_targets\n",
    "                        del model_input\n",
    "                        #del weightmaps\n",
    "                        del output\n",
    "                        torch.cuda.empty_cache()\n",
    "        \n",
    "                    else:\n",
    "                \n",
    "                        # forward pass\n",
    "                        input = torch.cat((img, coordmaps), dim = 1).type(torch.cuda.FloatTensor)\n",
    "                        output = model(input)\n",
    "                        if deep_supervision:\n",
    "                            output = output[-1]\n",
    "\n",
    "                        if model_config['final_sigmoid']:\n",
    "                            probability = output.cpu().numpy()\n",
    "                        else:\n",
    "                            probability = F.softmax(output, dim = 1).cpu().numpy()\n",
    "                    \n",
    "                    #Crop the patch to only use the center part\n",
    "                    patch_crop_size = reorganize_config['patch_crop_size']\n",
    "                    if patch_crop_size > 0:\n",
    "                        probability = probability[:,:,patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size,\n",
    "                                                  patch_crop_size:-patch_crop_size]\n",
    "\n",
    "                        \n",
    "                    ## Assemble image in loop!\n",
    "                    n, C, hp, wp, dp = probability.shape\n",
    "                    half_shape = torch.tensor([hp, wp, dp])/2\n",
    "                    hs, ws, ds = half_shape.type(torch.int)\n",
    "\n",
    "                    for cpt, pred in zip(list(cpts), list(probability)):\n",
    "                        #if np.sum(pred)/hs/ws/ds < 0.1:\n",
    "                        prob[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += pred\n",
    "                        rep[:,cpt[0] - hs:cpt[0] + hs, cpt[1] - ws:cpt[1] + ws, cpt[2] - ds:cpt[2] + ds] += 1\n",
    "\n",
    "                #Crop the image since we added padding when generating patches\n",
    "                prob = prob[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                rep = rep[:,half_patch[0]:-half_patch[0], half_patch[1]:-half_patch[1], half_patch[2]:-half_patch[2]]\n",
    "                rep[rep==0] = 1e-6\n",
    "\n",
    "                # Normalized by repetition\n",
    "                prob = prob/rep\n",
    "                seg_pred = np.argmax(prob, axis = 0).astype('float')\n",
    "                prob = np.moveaxis(prob,0,-1)\n",
    "\n",
    "                # compute gdsc\n",
    "                gdsc = computeGeneralizedDSC(Tseg, seg_pred)\n",
    "                sys.stdout.write(\"\\033[F\") #back to previous line \n",
    "                sys.stdout.write(\"\\033[K\") #clear line \n",
    "                print(\"    Prediction accuracy: \", gdsc)\n",
    "\n",
    "                #nib.save(nib.Nifti1Image(prob, affine), osp.join(c.predictDir, phase + \"_prob_\" + str(subjid) + \"_\" + side + \"_target.nii.gz\"))\n",
    "                nib.save(nib.Nifti1Image(seg_pred, affine), osp.join(c.predictDir, phase + \"_seg_\" + str(subjid) + \"_\" + side + \"_target.nii.gz\" ))\n",
    "\n",
    "\n",
    "print('Done')\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
